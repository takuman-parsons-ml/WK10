{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QshK8s21WBrf"
      },
      "source": [
        "# Week 10\n",
        "\n",
        "Text Processing and Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Hf8SXUwWOho"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Run the following 2 cells to import all necessary libraries and helpers for this week's exercises"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget -q https://github.com/PSAM-5020-2025S-A/5020-utils/raw/main/src/data_utils.py\n",
        "!wget -q https://github.com/PSAM-5020-2025S-A/5020-utils/raw/main/src/text_utils.py\n",
        "!wget -qO- https://github.com/PSAM-5020-2025S-A/5020-utils/raw/main/datasets/text/movie_reviews.tar.gz | tar xz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import string\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import NMF\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "from data_utils import MinMaxScaler\n",
        "from data_utils import object_from_json_url, classification_error, display_confusion_matrix\n",
        "\n",
        "from text_utils import get_top_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Text Classification\n",
        "\n",
        "Let's ____ using a movie review dataset.\n",
        "\n",
        "Load and look."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "reviews_df = pd.read_csv(\"./data/text/movie_reviews.csv\")\n",
        "reviews_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Features\n",
        "\n",
        "What can we say?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def count_characters(st):\n",
        "  return len(\"\".join(st.split()))\n",
        "\n",
        "def count_words(st):\n",
        "  return len(st.split(\" \"))\n",
        "\n",
        "def count_punctuation(st):\n",
        "  return len([c for c in st if c in string.punctuation])\n",
        "\n",
        "def count_digits(st):\n",
        "  return len([c for c in st if c in string.digits])\n",
        "\n",
        "def get_punctuation_pct(st):\n",
        "  return count_punctuation(st) / count_characters(st)\n",
        "\n",
        "def get_digit_pct(st):\n",
        "  return count_digits(st) / count_characters(st)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Apply to the `DataFrame`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "reviews_df[\"char_count\"] = reviews_df[\"review\"].apply(count_characters)\n",
        "reviews_df[\"word_count\"] = reviews_df[\"review\"].apply(count_words)\n",
        "reviews_df[\"punctuation_pct\"] = reviews_df[\"review\"].apply(get_punctuation_pct)\n",
        "reviews_df[\"digit_pct\"] = reviews_df[\"review\"].apply(get_digit_pct)\n",
        "\n",
        "reviews_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Look at some of these features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.scatter(reviews_df[\"word_count\"], reviews_df[\"punctuation_pct\"], c=reviews_df[\"sentiment\"])\n",
        "plt.title(\"Punctuation % x Word Count\")\n",
        "plt.show()\n",
        "\n",
        "plt.scatter(reviews_df[\"digit_pct\"], reviews_df[\"punctuation_pct\"], c=reviews_df[\"sentiment\"])\n",
        "plt.title(\"Digit % x Word Count\")\n",
        "plt.show()\n",
        "\n",
        "plt.scatter(reviews_df[\"word_count\"], reviews_df[\"char_count\"], c=reviews_df[\"sentiment\"])\n",
        "plt.title(\"Character Count x Word Count\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mScaler = MinMaxScaler()\n",
        "\n",
        "simple_feats_df = reviews_df.drop(columns=[\"review\", \"sentiment\"])\n",
        "simple_feats_scaled_df = mScaler.fit_transform(simple_feats_df)\n",
        "\n",
        "simple_feats_scaled_df[\"sentiment\"] = reviews_df[\"sentiment\"]\n",
        "\n",
        "simple_feats_scaled_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "reviews_train_df, reviews_test_df = train_test_split(simple_feats_scaled_df, test_size=0.2)\n",
        "\n",
        "reviews_train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mClassifier = RandomForestClassifier()\n",
        "\n",
        "train_feats = reviews_train_df.drop(columns=[\"sentiment\"])\n",
        "train_labels = reviews_train_df[\"sentiment\"]\n",
        "\n",
        "mClassifier.fit(train_feats, train_labels)\n",
        "\n",
        "train_preds = mClassifier.predict(train_feats)\n",
        "\n",
        "classification_error(train_labels, train_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_feats = reviews_test_df.drop(columns=[\"sentiment\"])\n",
        "test_labels = reviews_test_df[\"sentiment\"]\n",
        "\n",
        "test_preds = mClassifier.predict(test_feats)\n",
        "\n",
        "classification_error(test_labels, test_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ü§î\n",
        "\n",
        "Bag of words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "reviews_df = pd.read_csv(\"./data/text/movie_reviews.csv\")\n",
        "\n",
        "reviews_train_df, reviews_test_df = train_test_split(reviews_df, test_size=0.2)\n",
        "reviews_train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mCV = CountVectorizer(stop_words=\"english\", min_df=5, max_df=0.75, max_features=10_000)\n",
        "\n",
        "reviews_train_vct = mCV.fit_transform(reviews_train_df[\"review\"])\n",
        "reviews_test_vct = mCV.transform(reviews_test_df[\"review\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "reviews_train_vct"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Working with sparse matrices.\n",
        "\n",
        "Words counted:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab = mCV.get_feature_names_out()\n",
        "vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get words in a review"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mCV.inverse_transform(reviews_train_vct[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get indices of words in a review:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "reviews_train_vct[0].nonzero()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get counts of those words in a review"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "reviews_train_vct[reviews_train_vct[0].nonzero()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get words ordered by frequency:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "review = reviews_train_vct[0]\n",
        "\n",
        "n_words = len(review.nonzero()[0])\n",
        "\n",
        "sorted_idxs = (-review.toarray()[0]).argsort()\n",
        "\n",
        "vocab[sorted_idxs[:n_words]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from text_utils import get_top_words\n",
        "\n",
        "get_top_words(reviews_train_vct[0], vocab, n_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mClassifier = RandomForestClassifier()\n",
        "\n",
        "train_labels = reviews_train_df[\"sentiment\"]\n",
        "\n",
        "mClassifier.fit(reviews_train_vct, train_labels)\n",
        "\n",
        "train_preds = mClassifier.predict(reviews_train_vct)\n",
        "\n",
        "classification_error(train_labels, train_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_labels = reviews_test_df[\"sentiment\"]\n",
        "\n",
        "test_preds = mClassifier.predict(reviews_test_vct)\n",
        "\n",
        "classification_error(test_labels, test_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Naive Bayes\n",
        "\n",
        "Some equations\n",
        "\n",
        "Bernouli vs gaussian vs categorical vs multinomial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Order of words ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mCV = CountVectorizer(stop_words=\"english\", min_df=5, max_df=0.75, max_features=50_000, ngram_range=(2, 2))\n",
        "\n",
        "reviews_train_vct = mCV.fit_transform(reviews_train_df[\"review\"])\n",
        "reviews_test_vct = mCV.transform(reviews_test_df[\"review\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab = mCV.get_feature_names_out()\n",
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mCV.inverse_transform(reviews_train_vct[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "get_top_words(reviews_train_vct[0], vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mClassifier = MultinomialNB()\n",
        "\n",
        "train_labels = reviews_train_df[\"sentiment\"]\n",
        "\n",
        "mClassifier.fit(reviews_train_vct, train_labels)\n",
        "\n",
        "train_preds = mClassifier.predict(reviews_train_vct)\n",
        "\n",
        "classification_error(train_labels, train_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_labels = reviews_test_df[\"sentiment\"]\n",
        "\n",
        "test_preds = mClassifier.predict(reviews_test_vct)\n",
        "\n",
        "classification_error(test_labels, test_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Slightly smarter counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mTfidV = TfidfVectorizer(stop_words=\"english\", min_df=5, max_df=0.75, max_features=50_000, ngram_range=(1, 1))\n",
        "\n",
        "reviews_train_vct = mTfidV.fit_transform(reviews_train_df[\"review\"])\n",
        "reviews_test_vct = mTfidV.transform(reviews_test_df[\"review\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab = mTfidV.get_feature_names_out()\n",
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mTfidV.inverse_transform(reviews_train_vct[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "get_top_words(reviews_train_vct[0], vocab, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mClassifier = MultinomialNB()\n",
        "\n",
        "train_labels = reviews_train_df[\"sentiment\"]\n",
        "\n",
        "mClassifier.fit(reviews_train_vct, train_labels)\n",
        "\n",
        "train_preds = mClassifier.predict(reviews_train_vct)\n",
        "\n",
        "classification_error(train_labels, train_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_labels = reviews_test_df[\"sentiment\"]\n",
        "\n",
        "test_preds = mClassifier.predict(reviews_test_vct)\n",
        "\n",
        "classification_error(test_labels, test_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TODO: TFIDF with ngrams ??"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Can we extract other info ? Cluster ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mClust = KMeans(n_clusters=8)\n",
        "reviews_train_km = mClust.fit_predict(reviews_train_vct)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "get_top_words(mClust.cluster_centers_, mTfidV.get_feature_names_out(), 8)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Can we do better ?\n",
        "\n",
        "We're clustering over 40k features .... very sparse space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mNmf = NMF(n_components=8)\n",
        "reviews_train_nmf = mNmf.fit_transform(reviews_train_vct)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "get_top_words(mNmf.components_, mTfidV.get_feature_names_out(), 6)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Classification for other dataset.\n",
        "\n",
        "Amazon products"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Text Analysis is a major application field for machine learning algorithms. However the raw data, a sequence of symbols cannot be fed directly to the algorithms themselves as most of them expect numerical feature vectors with a fixed size rather than the raw text documents with variable length.\n",
        "\n",
        "Tokenizing: is _____ ...."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "One way to do text is Bag of Words:\n",
        "\n",
        "https://letsdatascience.com/bag-of-words/\n",
        "\n",
        "https://www.kaggle.com/code/samuelcortinhas/nlp3-bag-of-words-and-similarity\n",
        "\n",
        "https://letsdatascience.com/word-embeddings/\n",
        "\n",
        "- each individual token occurrence frequency is treated as a feature.\n",
        "- the vector of all the token frequencies for a given document is considered a multivariate sample.\n",
        "\n",
        "A corpus of documents can thus be represented by a matrix with one row per document and one column per token (e.g. word) occurring in the corpus.\n",
        "\n",
        "We call vectorization the general process of turning a collection of text documents into numerical feature vectors. This specific strategy (tokenization, counting and normalization) is called the Bag of Words or ‚ÄúBag of n-grams‚Äù representation. Documents are described by word occurrences while completely ignoring the relative position information of the words in the document.\n",
        "\n",
        "A collection of unigrams (what bag of words is) cannot capture phrases and multi-word expressions, effectively disregarding any word order dependence. Additionally, the bag of words model doesn‚Äôt account for potential misspellings or word derivations.\n",
        "\n",
        "N-grams to the rescue! Instead of building a simple collection of unigrams (n=1), one might prefer a collection of bigrams (n=2), where occurrences of pairs of consecutive words are counted.\n",
        "\n",
        "`CountVectorizer()` can have ngrams using ngram_range."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In a large text corpus, some words appear with higher frequency (e.g. ‚Äúthe‚Äù, ‚Äúa‚Äù, ‚Äúis‚Äù in English) and do not carry meaningful information about the actual contents of a document. If we were to feed the word count data directly to a classifier, those very common terms would shadow the frequencies of rarer yet more informative terms. In order to re-weight the count features into floating point values suitable for usage by a classifier it is very common to use the tf-idf transform as implemented by the `TfidfTransformer()`. TF stands for ‚Äúterm-frequency‚Äù while ‚Äútf-idf‚Äù means term-frequency times inverse document-frequency.\n",
        "\n",
        "`CountVectorizer() + TfidfTransformer() = TfidfVectorizer()`\n",
        "\n",
        "Vectorizer parameters:\n",
        "\n",
        "- Ignore terms that appear in more than 50% of the documents (set by max_df=0.5)\n",
        "\n",
        "- Ignore terms that are not present in at least 5 documents (set by min_df=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Clustering\n",
        "\n",
        "`TruncatedSVD()`:\n",
        "This transformer performs linear dimensionality reduction by means of truncated singular value decomposition (SVD). Contrary to PCA, this estimator does not center the data before computing the singular value decomposition. This means it can work with sparse matrices efficiently.\n",
        "\n",
        "`Non-Negative Matrix Factorization (NMF)`\n",
        "Find two non-negative matrices, i.e. matrices with all non-negative elements, (W, H) whose product approximates the non-negative matrix X. This factorization can be used for example for dimensionality reduction, source separation or topic extraction.\n",
        "\n",
        "\n",
        "### Top terms per cluster\n",
        "Since TfidfVectorizer can be inverted we can identify the cluster centers, which provide an intuition of the most influential words for each cluster."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "However, if documents in the same corpus have very different lengths, or the vocabulary is extremely large, these metrics become less reliable.\n",
        "\n",
        "Instead, in the NLP domain it is much more common to use Cosine Similarity. This measures the cosine of the angle between any two points (more precisely their vectors starting from the origin). The closer the score 1, the smaller the angle between the vectors and the more similar the documents are."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPxe2qYxIG7EblrvD1C4Pmv",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.17 ('hf-model')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "89e384cab7c47fb35ec95d2248b519cf922ee174880eed636c26cdfb6c4df768"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
